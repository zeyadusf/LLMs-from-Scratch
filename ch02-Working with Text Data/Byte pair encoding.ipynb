{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Byte pair encoding\n",
    "\n",
    "> A detailed discussion and implementation of BPE is out of the scope of this\n",
    "book, but in short, it builds its vocabulary by iteratively merging frequent\n",
    "characters into subwords and frequent subwords into words. For example,\n",
    "BPE starts with adding all individual single characters to its vocabulary (\"a\",\n",
    "\"b\", ...). In the next stage, it merges character combinations that frequently\n",
    "occur together into subwords. For example, \"d\" and \"e\" may be merged into\n",
    "the subword \"de,\" which is common in many English words like \"define\",\n",
    "\"depend\", \"made\", and \"hidden\". The merges are determined by a frequency\n",
    "cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install tiktoken\n",
    "! pip install -q tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from importlib_metadata import version\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version :0.6.0\n"
     ]
    }
   ],
   "source": [
    "print(f'tiktoken version :{version(\"tiktoken\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode : [15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 1059, 430, 13]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "text = \"Hello, do you like tea? <|endoftext|> In the sunlit terra.\"\n",
    "\n",
    "integers = tokenizer.encode(text,allowed_special={\"<|endoftext|>\"})\n",
    "print(\"encode :\",integers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decode : Hello, do you like tea? <|endoftext|> In the sunlit terra.\n"
     ]
    }
   ],
   "source": [
    "print('decode :',tokenizer.decode(integers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 367, 2885, 1464, 1807, 3619, 402, 271, 10899, 2138]\n"
     ]
    }
   ],
   "source": [
    "from Tokenizer import read_txt # 2.3 & 2.4 Tokenizer.py\n",
    "txt_file = read_txt(r'E:\\Courses\\LLMs\\LLMs-from-Scratch\\ch02-Working with Text Data\\data\\the-verdict.txt')\n",
    "integers = tokenizer.encode(txt_file)\n",
    "\n",
    "print(integers[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decode : I HAD always thought Jack Gisburn rather\n"
     ]
    }
   ],
   "source": [
    "print('decode :',tokenizer.decode(integers[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# UNK words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode : [57, 2959, 324]\n",
      "decode : Zeyad\n",
      "-*-*-*-*-*-*-*-*-*-*\n",
      "encode : [33901, 86, 343, 86, 220, 959]\n",
      "decode : Akwirw ier\n",
      "-*-*-*-*-*-*-*-*-*-*\n"
     ]
    }
   ],
   "source": [
    "text = [\"Zeyad\",\"Akwirw ier\"]\n",
    "for i in text:\n",
    "  integers = tokenizer.encode(i)\n",
    "  print(\"encode :\",integers)\n",
    "  print('decode :',tokenizer.decode(integers))\n",
    "  print('-*'*10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
