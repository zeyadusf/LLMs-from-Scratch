{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slidingWindow import llm_dataloader\n",
    "from Processed import read_txt\n",
    "import torch\n",
    "from torch.nn import Embedding\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1286/1286 [00:00<00:00, 15318.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize parameters\n",
    "raw_text = read_txt(r'E:\\Courses\\LLMs\\LLMs-from-Scratch\\ch02-Working with Text Data\\data\\the-verdict.txt')\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "max_length = 4\n",
    "batch_size = 8\n",
    "stride = max_length \n",
    "shuffle = False\n",
    "drop_last = False\n",
    "# \n",
    "output_dim = 256\n",
    "vocab_size = 50257 #after use BPE \n",
    "token_embedding_layer = Embedding(vocab_size,output_dim) \n",
    "context_length = max_length\n",
    "pos_embedding_layer = Embedding(context_length,output_dim)\n",
    "# \n",
    "dataloader = llm_dataloader(raw_text,tokenizer,batch_size,max_length,stride,shuffle,drop_last)\n",
    "# \n",
    "dataiter = iter(dataloader)\n",
    "inputs, targets = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      "tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "Input Shape:torch.Size([8, 4])\n",
      "-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*-*\n",
      "Targets:\n",
      "tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n",
      " Targets Shape:torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f'Token IDs:\\n{inputs}\\nInput Shape:{inputs.shape}')\n",
    "print('-*'*20)\n",
    "print(f'Targets:\\n{targets}\\n Targets Shape:{targets.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Embeddings Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5899, -2.2650, -1.0058,  ...,  1.0582, -1.3516, -0.2528],\n",
      "         [-0.6102,  0.5806,  0.1923,  ..., -0.2797, -0.0393,  0.6880],\n",
      "         [ 0.1064,  1.1381,  0.0068,  ...,  1.6583,  0.8139, -0.7083],\n",
      "         [-1.4293, -0.5136,  0.5766,  ...,  2.0875, -1.1991,  0.3011]],\n",
      "\n",
      "        [[ 0.6475,  0.5380,  0.3378,  ...,  1.6128, -1.2153,  0.0962],\n",
      "         [-2.0165,  2.0151, -0.9248,  ...,  0.5406,  1.1366, -1.1557],\n",
      "         [ 0.0129,  0.2496, -0.0598,  ..., -1.8037, -0.2549,  0.8862],\n",
      "         [-0.6942, -0.0035,  0.4303,  ...,  0.2214,  0.4662,  1.2901]]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings= token_embedding_layer(inputs)\n",
    "\n",
    "print(token_embeddings[:2]) # print 2 embedding \n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.8986e-01, -2.2650e+00, -1.0058e+00, -4.0477e-01,  2.3961e-02,\n",
       "        -8.4919e-01,  2.1994e+00,  1.8230e-01,  1.1145e+00, -6.3978e-01,\n",
       "         6.5116e-01, -2.7994e-01,  2.4138e-02,  1.0118e+00, -1.7863e+00,\n",
       "        -3.3997e-01,  2.4021e-01, -8.6360e-01,  1.6234e+00, -6.4908e-01,\n",
       "        -4.9242e-01,  4.7222e-01,  7.0927e-01, -1.3238e-01, -1.2507e+00,\n",
       "         1.0185e+00, -4.7168e-01, -4.7430e-01,  2.3675e+00, -9.7850e-03,\n",
       "         4.4780e-01, -1.2609e+00, -9.2068e-01,  1.9468e-01, -1.1174e+00,\n",
       "        -1.0782e+00,  3.4360e-01, -1.6371e+00, -8.2822e-01,  1.0826e+00,\n",
       "         1.0101e+00, -4.1291e-01, -4.3896e-01,  8.3303e-01,  1.9196e+00,\n",
       "        -1.1700e+00,  1.0673e+00, -3.9927e-02, -1.8670e+00, -8.4616e-01,\n",
       "         4.8809e-01,  1.2945e+00,  6.5960e-01, -9.0762e-01,  1.6333e+00,\n",
       "        -1.0016e+00,  4.1135e-01,  4.6505e-01,  7.7219e-02, -3.3204e-01,\n",
       "         2.4387e-01,  4.3717e-01,  1.3726e+00,  2.0943e-01,  1.7603e-01,\n",
       "         3.0125e-01, -4.3039e-02,  1.0131e+00,  2.9849e-01,  8.4262e-01,\n",
       "         1.3876e+00,  1.1042e+00,  2.0797e-01,  6.5397e-01, -1.0211e-02,\n",
       "         1.9893e-01,  1.1284e+00,  2.1934e-01, -1.4798e-01, -3.6450e-01,\n",
       "         3.1617e-01,  1.8975e+00,  7.9903e-01,  1.4291e+00,  1.0437e+00,\n",
       "         5.1041e-01,  1.8482e-01,  4.1141e-01,  1.6968e-01, -2.9861e-01,\n",
       "         8.1217e-01, -8.3307e-01, -1.8167e+00, -6.1469e-01, -7.1184e-01,\n",
       "         1.6393e+00,  2.1331e-04,  1.2693e+00, -6.8486e-01, -1.0848e+00,\n",
       "         1.2707e+00,  7.2815e-01, -2.2600e-02,  2.8811e-01, -7.3816e-01,\n",
       "        -1.8015e+00,  2.5433e-01, -1.7860e-01, -1.3086e+00, -1.6309e+00,\n",
       "        -1.4523e+00, -5.8557e-01, -1.1705e+00, -1.4918e+00, -5.0575e-01,\n",
       "        -1.9124e+00,  1.5263e+00,  4.7762e-01, -4.0760e-01, -2.0348e+00,\n",
       "        -2.4848e-01,  1.8351e+00, -4.3945e-01,  3.3020e-01,  1.9768e-01,\n",
       "        -1.0104e+00,  7.6695e-01,  3.0865e-01, -1.1004e+00, -1.8583e+00,\n",
       "        -2.5150e+00,  7.7446e-01, -1.2773e-01,  3.3735e-01, -5.7457e-01,\n",
       "        -1.7621e+00,  2.1965e+00,  1.2723e+00, -1.3460e-01, -2.9833e-01,\n",
       "         7.4152e-02, -3.1506e-01,  8.9747e-01,  2.0474e+00,  1.5154e+00,\n",
       "        -1.0294e-01,  3.4229e-01, -3.7469e-01, -7.7894e-02, -1.1721e+00,\n",
       "         1.1824e-01,  1.5479e+00, -6.1798e-01, -7.0212e-01,  6.5872e-01,\n",
       "         1.8709e-01, -3.4042e-01, -5.9676e-01, -9.5200e-02,  1.0070e+00,\n",
       "        -1.4710e+00, -1.1366e+00, -8.7889e-01, -6.5140e-03, -9.2775e-01,\n",
       "        -7.1409e-01, -2.0585e+00, -7.7647e-01,  7.9652e-01, -9.0032e-01,\n",
       "         1.2345e+00,  7.9340e-01,  5.5415e-02,  6.5378e-01, -7.2231e-01,\n",
       "        -9.7924e-01, -1.2949e+00,  2.9187e+00, -5.3154e-01, -1.3961e+00,\n",
       "        -1.2431e+00,  4.6696e-01,  1.4899e+00,  7.8353e-01, -7.4812e-02,\n",
       "         1.6975e-01,  1.0961e+00,  5.7856e-01, -9.3968e-01,  3.2345e-01,\n",
       "         2.0776e+00,  1.1124e+00,  3.6081e-02,  2.0567e+00,  6.5138e-01,\n",
       "        -3.9743e-01, -1.1150e+00,  1.3246e-01, -1.8290e-01,  2.0788e-01,\n",
       "         1.0789e+00,  4.2228e-01, -1.9024e-01, -4.9201e-01, -2.5501e-01,\n",
       "         1.1147e+00, -5.0658e-02, -3.2325e-01, -9.6488e-01,  3.0018e-01,\n",
       "        -4.6105e-01,  3.0100e-01,  2.1480e-01,  1.0826e+00, -3.8033e-01,\n",
       "         2.3083e-01,  3.0594e-01,  1.0493e+00, -7.4680e-01, -1.3618e+00,\n",
       "        -1.1341e+00, -4.5661e-01,  7.5620e-01,  5.0872e-01, -6.0756e-01,\n",
       "         3.0023e-01,  4.4655e-02, -5.9770e-02, -3.0320e-01, -1.3675e+00,\n",
       "         1.0181e+00, -9.3261e-01, -1.4203e+00, -1.2666e+00, -1.8726e+00,\n",
       "        -2.8584e-01, -9.5696e-01, -2.7598e-01,  1.0477e-01, -1.5905e-01,\n",
       "         1.3226e+00,  3.3927e-01,  1.3307e+00,  1.4234e+00, -4.3422e-01,\n",
       "        -1.5982e+00,  2.3205e+00, -5.5392e-01,  1.0846e+00,  9.2105e-01,\n",
       "        -4.9614e-01, -6.8078e-01, -1.6621e+00,  1.0582e+00, -1.3516e+00,\n",
       "        -2.5278e-01], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings[0][0] # print one raw "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Position Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1176,  0.4917,  0.2027,  2.3352,  0.5601,  0.1329,  0.7945, -0.8301,\n",
      "        -1.4458,  0.2496,  0.6097, -0.3420, -0.5437,  0.6284, -0.7748, -2.3801,\n",
      "         0.4767, -0.5610,  0.9331,  0.2100, -1.4567,  0.6408,  0.9580, -0.2480,\n",
      "         1.5920, -0.6674, -0.0573,  0.8251, -0.0382, -2.4458,  1.2393, -0.2022,\n",
      "         1.4708, -0.6372, -0.6738, -0.2046, -0.4991,  0.6994,  1.3749,  1.0307,\n",
      "        -1.0226,  0.7088, -2.2867, -0.5230, -0.3672, -1.1590,  0.1260, -1.0807,\n",
      "        -0.0831,  0.1392,  0.3289,  0.4166,  0.0140,  0.7035,  0.1439, -0.5006,\n",
      "         0.8507,  0.6613, -0.4725,  1.0842,  0.7901, -1.1069, -0.0389, -0.2469,\n",
      "        -0.2663, -1.5507, -0.8488,  0.3759,  0.8536,  0.5837,  0.1206, -0.4834,\n",
      "        -1.8719,  0.8002,  1.0162, -2.0963,  1.2174, -1.4686,  1.2448,  0.6842,\n",
      "         0.6862,  0.7614,  0.0150,  1.8148, -1.9920,  0.7116, -0.0224, -0.0061,\n",
      "         0.0950,  0.2777,  0.2102, -0.2983, -1.6750,  1.0517,  0.1830, -0.5232,\n",
      "        -0.3899, -1.0786, -0.0568, -0.1550,  0.3945, -0.4993, -0.3865,  1.9352,\n",
      "        -0.5602,  0.0320,  0.4071,  0.2592,  0.2719, -1.0394, -0.5770, -1.9729,\n",
      "        -1.4707, -1.8275,  0.4965,  0.3610,  2.1121,  1.4739, -0.5940,  0.6884,\n",
      "         0.8685, -1.4642, -0.4612, -0.9038,  0.0353, -1.2068,  0.1791,  1.5343,\n",
      "         0.2340, -0.2081, -1.0511, -1.1691,  0.0884, -1.6693,  2.1401,  0.8830,\n",
      "        -0.5555, -0.2039, -0.5220, -1.5642, -0.8707, -0.1866,  0.5258,  2.0061,\n",
      "         1.0788, -0.2450, -0.8800,  2.6628,  0.9425, -0.5993,  0.5769, -0.8408,\n",
      "         0.2578,  0.5416, -0.8057,  1.8069, -0.9673, -0.0682,  1.2349, -1.6319,\n",
      "        -3.3838,  1.3233,  0.1933, -1.7347, -0.5035, -1.0452, -1.2458,  0.7582,\n",
      "         1.8144,  0.8678, -1.3143,  0.8577,  1.2849, -0.7946,  0.3400,  0.2084,\n",
      "        -1.0087, -0.4454, -1.2725,  0.7636, -0.2098, -0.9500,  0.1460, -0.5203,\n",
      "        -2.1878,  0.5259,  2.5866, -1.7256, -1.5079,  1.1920,  1.6602,  0.1450,\n",
      "         0.0905,  0.4004,  0.4799, -1.0368, -1.1769,  1.2105, -0.4701, -0.9062,\n",
      "        -0.2400, -1.9383, -0.5333,  0.8340,  0.2500,  2.5041, -2.2275, -0.4915,\n",
      "         1.0440,  0.7845,  0.6371, -0.8208, -0.3037,  0.6126, -1.3632, -0.0099,\n",
      "         0.7402,  1.1539, -1.5345, -1.1460,  0.3494,  0.4322,  0.2177,  0.0907,\n",
      "         0.4058,  1.3645,  0.0409,  1.1415, -0.5323, -1.1526,  1.0084, -0.1010,\n",
      "         0.8391, -0.5197, -0.6872, -0.0538,  0.4685,  0.0257, -0.8968, -0.3884,\n",
      "        -1.1761, -1.5713,  0.4960, -0.6309, -0.3186, -0.1962, -1.2666,  0.3657,\n",
      "         1.6072, -0.1717,  1.0929, -2.2039,  0.8889,  0.4754, -1.0792, -0.4098],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(pos_embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings \n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7074, -1.7732, -0.8032,  ...,  1.5336, -2.4308, -0.6625],\n",
       "        [-0.2020,  0.1934,  0.6753,  ..., -2.9168, -1.3860,  0.8789],\n",
       "        [ 0.5474,  0.6868, -0.0635,  ...,  2.7347,  0.8467, -1.7815],\n",
       "        [-1.6508, -0.5596, -0.1177,  ...,  3.7795, -2.9219, -1.5049]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
