{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install tiktoken\n",
    "! pip install -q tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Processed import read_txt\n",
    "from slidingWindow import LLMDataset ,llm_dataloader\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = read_txt(r'E:\\Courses\\LLMs\\LLMs-from-Scratch\\ch02-Working with Text Data\\data\\the-verdict.txt')\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "max_length = 6\n",
    "batch_size = 8\n",
    "stride = max_length # to avoid overlap between batches and more overlap could lead to increased overfitting.\n",
    "shuffle = False\n",
    "drop_last = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 857/857 [00:00<00:00, 23819.74it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = llm_dataloader(raw_text,tokenizer,batch_size,max_length,stride,shuffle,drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: \n",
      "tensor([[   40,   367,  2885,  1464,  1807,  3619],\n",
      "        [  402,   271, 10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257,   922,  5891],\n",
      "        [ 1576,   438,   568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502,   284,  3285],\n",
      "        [  326,    11,   287,   262,  6001,   286],\n",
      "        [  465, 13476,    11,   339,   550,  5710],\n",
      "        [  465, 12036,    11,  6405,   257,  5527]]) \n",
      "target: \n",
      "tensor([[  367,  2885,  1464,  1807,  3619,   402],\n",
      "        [  271, 10899,  2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922,  5891,  1576],\n",
      "        [  438,   568,   340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284,  3285,   326],\n",
      "        [   11,   287,   262,  6001,   286,   465],\n",
      "        [13476,    11,   339,   550,  5710,   465],\n",
      "        [12036,    11,  6405,   257,  5527, 27075]])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(dataset)\n",
    "firstbatch =next(dataiter)\n",
    "print(f'inputs: \\n{firstbatch[0]} \\ntarget: \\n{firstbatch[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: \n",
      "tensor([[27075,    11,   290,  4920,  2241,   287],\n",
      "        [  257,  4489,    64,   319,   262, 34686],\n",
      "        [41976,    13,   357, 10915,   314,  2138],\n",
      "        [ 1807,   340,   561,   423,   587, 10598],\n",
      "        [  393, 28537,  2014,   198,   198,     1],\n",
      "        [  464,  6001,   286,   465, 13476,     1],\n",
      "        [  438,  5562,   373,   644,   262,  1466],\n",
      "        [ 1444,   340,    13,   314,   460,  3285]]) \n",
      "target: \n",
      "tensor([[   11,   290,  4920,  2241,   287,   257],\n",
      "        [ 4489,    64,   319,   262, 34686, 41976],\n",
      "        [   13,   357, 10915,   314,  2138,  1807],\n",
      "        [  340,   561,   423,   587, 10598,   393],\n",
      "        [28537,  2014,   198,   198,     1,   464],\n",
      "        [ 6001,   286,   465, 13476,     1,   438],\n",
      "        [ 5562,   373,   644,   262,  1466,  1444],\n",
      "        [  340,    13,   314,   460,  3285,  9074]])\n"
     ]
    }
   ],
   "source": [
    "secondbatch =next(dataiter)\n",
    "print(f'inputs: \\n{secondbatch[0]} \\ntarget: \\n{secondbatch[1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
